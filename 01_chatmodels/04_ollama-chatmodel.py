# Import necessary modules
from langchain_ollama import ChatOllama  # Import the ChatOllama model from Langchain for Llama models
from dotenv import load_dotenv  # Import to load environment variables from a .env file

# Load environment variables (e.g., API keys, model credentials) from the .env file
load_dotenv()

# Initialize the ChatOllama model with the specified model version 'llama3.1'
# This model will be used to generate a response for the given input
model = ChatOllama(model="llama3.1")

# Invoke the model with a query asking "What is the meaning of life?"
# The invoke method sends the query to the model and retrieves a response
response = model.invoke("What is the meaning of Life?")

# Print the content of the response generated by the model
print(response.content)